{
  "task_idx": 0,
  "best_speedup": 0.7659574468085107,
  "num_metric_calls": 11,
  "best_at_metric_call": 9,
  "best_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# Define the custom CUDA kernel for 3D tensor-matrix multiplication\nmatmul_3d_source = \"\"\"\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n\ntorch::Tensor matmul_3d_cuda(torch::Tensor A, torch::Tensor B) {\n    // Get dimensions\n    int N = A.size(0);\n    int M = A.size(1);\n    int K = A.size(2);\n    int L = B.size(1);\n    \n    // Create output tensor\n    auto C = torch::empty({N, M, L}, A.options());\n    \n    // Get pointers to tensor data\n    float* A_ptr = A.data_ptr<float>();\n    float* B_ptr = B.data_ptr<float>();\n    float* C_ptr = C.data_ptr<float>();\n    \n    // Initialize cuBLAS\n    cublasHandle_t handle;\n    cublasCreate(&handle);\n    \n    // Set up constants for GEMM\n    float alpha = 1.0f;\n    float beta = 0.0f;\n    \n    // Use cublasSgemmStridedBatched for better performance\n    // This avoids the loop and processes all batches in a single call\n    cublasSgemmStridedBatched(handle,\n                             CUBLAS_OP_N, CUBLAS_OP_N,\n                             L, M, K,\n                             &alpha,\n                             B_ptr, L, 0,            // Matrix B, stride 0 (reused for each batch)\n                             A_ptr, K, M*K,          // Matrix A, stride M*K between batches\n                             &beta,\n                             C_ptr, L, M*L,          // Matrix C, stride M*L between batches\n                             N);                     // Number of batches\n    \n    // Clean up\n    cublasDestroy(handle);\n    \n    return C;\n}\n\"\"\"\n\nmatmul_3d_cpp_source = \"\"\"\ntorch::Tensor matmul_3d_cuda(torch::Tensor A, torch::Tensor B);\n\"\"\"\n\n# Compile the inline CUDA code for 3D tensor-matrix multiplication\nmatmul_3d = load_inline(\n    name=\"matmul_3d\",\n    cpp_sources=matmul_3d_cpp_source,\n    cuda_sources=matmul_3d_source,\n    functions=[\"matmul_3d_cuda\"],\n    verbose=True,\n    with_cuda=True,\n    extra_ldflags=[\"-lcublas\"]\n)\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs 3D tensor-matrix multiplication with optimized custom CUDA implementation.\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n        self.matmul_3d = matmul_3d\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs 3D tensor-matrix multiplication.\n\n        Args:\n            A (torch.Tensor): Input 3D tensor of shape (N, M, K).\n            B (torch.Tensor): Input matrix of shape (K, L).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (N, M, L), resulting from the multiplication of A and B.\n        \"\"\"\n        # Move tensors to CUDA if they're not already there\n        if not A.is_cuda:\n            A = A.cuda()\n        if not B.is_cuda:\n            B = B.cuda()\n            \n        # Use our custom CUDA implementation\n        return self.matmul_3d.matmul_3d_cuda(A, B)",
  "duration_seconds": 332.97074270248413,
  "history": [
    {
      "attempt": 1,
      "score": 0.0,
      "best_score": 0.0,
      "is_new_best": false,
      "iteration_found": 0
    },
    {
      "attempt": 2,
      "score": 0.0,
      "best_score": 0.0,
      "is_new_best": false,
      "iteration_found": 1
    },
    {
      "attempt": 3,
      "score": 0.0,
      "best_score": 0.0,
      "is_new_best": false,
      "iteration_found": 2
    },
    {
      "attempt": 4,
      "score": 0.0,
      "best_score": 0.0,
      "is_new_best": false,
      "iteration_found": 3
    },
    {
      "attempt": 5,
      "score": 0.0,
      "best_score": 0.0,
      "is_new_best": false,
      "iteration_found": 4
    },
    {
      "attempt": 6,
      "score": 0.763888888888889,
      "best_score": 0.763888888888889,
      "is_new_best": true,
      "iteration_found": 5
    },
    {
      "attempt": 7,
      "score": 0.0,
      "best_score": 0.763888888888889,
      "is_new_best": false,
      "iteration_found": 6
    },
    {
      "attempt": 8,
      "score": 0.7500000000000001,
      "best_score": 0.763888888888889,
      "is_new_best": false,
      "iteration_found": 7
    },
    {
      "attempt": 9,
      "score": 0.13757961783439493,
      "best_score": 0.763888888888889,
      "is_new_best": false,
      "iteration_found": 8
    },
    {
      "attempt": 10,
      "score": 0.7659574468085107,
      "best_score": 0.7659574468085107,
      "is_new_best": true,
      "iteration_found": 9
    },
    {
      "attempt": 11,
      "score": 0.0,
      "best_score": 0.7659574468085107,
      "is_new_best": false,
      "iteration_found": 10
    }
  ],
  "metrics": {
    "combined_score": 0.7659574468085107
  },
  "settings": {
    "model": "claude-3.7-sonnet",
    "max_iterations": 10,
    "num_workers": 1,
    "evolution_strategy": "full_rewrite",
    "population_size": 50,
    "num_correct_trials": 1,
    "num_perf_trials": 5
  }
}