{
  "task_idx": 13,
  "best_speedup": 1.2274678111587982,
  "num_metric_calls": 25,
  "num_iterations_total": 10,
  "num_candidates_discovered": 5,
  "best_at_metric_call": 16,
  "best_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# Define improved custom CUDA kernel for optimized matrix multiplication with small K dimension\nmatmul_source = \"\"\"\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cuda.h>\n\n// Improved kernel for large M,N and small K dimensions\n// Uses vectorized loads/stores, improved memory access patterns and increased occupancy\ntemplate <int BLOCK_SIZE_M, int BLOCK_SIZE_N, int TILE_SIZE>\n__global__ void matmul_kernel_small_k_improved(\n    const float* __restrict__ A, \n    const float* __restrict__ B, \n    float* __restrict__ C, \n    const int M, const int N, const int K) {\n    \n    // Thread block handles a BLOCK_SIZE_M x BLOCK_SIZE_N output tile\n    const int bx = blockIdx.x;\n    const int by = blockIdx.y;\n    const int tx = threadIdx.x;\n    const int ty = threadIdx.y;\n    \n    // Each thread computes TILE_SIZE x TILE_SIZE outputs\n    const int row_base = by * BLOCK_SIZE_M + ty;\n    const int col_base = bx * BLOCK_SIZE_N + tx;\n    \n    // Output register tile\n    float acc[TILE_SIZE][TILE_SIZE] = {0.0f};\n    \n    // Main loop over K dimension (which is small)\n    for (int k = 0; k < K; k++) {\n        // Load A tile into registers - vectorized loads where possible\n        float a_reg[TILE_SIZE];\n        #pragma unroll\n        for (int i = 0; i < TILE_SIZE; i++) {\n            const int row = row_base + i * (BLOCK_SIZE_M / TILE_SIZE);\n            a_reg[i] = (row < M) ? A[row * K + k] : 0.0f;\n        }\n        \n        // Load B tile into registers - vectorized loads where possible\n        float b_reg[TILE_SIZE];\n        #pragma unroll\n        for (int i = 0; i < TILE_SIZE; i++) {\n            const int col = col_base + i * (BLOCK_SIZE_N / TILE_SIZE);\n            b_reg[i] = (col < N) ? B[k * N + col] : 0.0f;\n        }\n        \n        // Compute outer product for this k\n        #pragma unroll\n        for (int i = 0; i < TILE_SIZE; i++) {\n            #pragma unroll\n            for (int j = 0; j < TILE_SIZE; j++) {\n                acc[i][j] += a_reg[i] * b_reg[j];\n            }\n        }\n    }\n    \n    // Store results to global memory\n    #pragma unroll\n    for (int i = 0; i < TILE_SIZE; i++) {\n        const int row = row_base + i * (BLOCK_SIZE_M / TILE_SIZE);\n        if (row >= M) continue;\n        \n        #pragma unroll\n        for (int j = 0; j < TILE_SIZE; j++) {\n            const int col = col_base + j * (BLOCK_SIZE_N / TILE_SIZE);\n            if (col < N) {\n                C[row * N + col] = acc[i][j];\n            }\n        }\n    }\n}\n\n// Alternative implementation using shared memory for very wide matrices\ntemplate <int BLOCK_SIZE_M, int BLOCK_SIZE_N, int BLOCK_SIZE_K>\n__global__ void matmul_kernel_small_k_shared(\n    const float* __restrict__ A, \n    const float* __restrict__ B, \n    float* __restrict__ C, \n    const int M, const int N, const int K) {\n    \n    // Shared memory for tiles\n    __shared__ float As[BLOCK_SIZE_M][BLOCK_SIZE_K];\n    __shared__ float Bs[BLOCK_SIZE_K][BLOCK_SIZE_N];\n    \n    const int tx = threadIdx.x;\n    const int ty = threadIdx.y;\n    const int bx = blockIdx.x;\n    const int by = blockIdx.y;\n    \n    // Global row and column indices\n    const int row = by * BLOCK_SIZE_M + ty;\n    const int col = bx * BLOCK_SIZE_N + tx;\n    \n    // Accumulator for dot product\n    float acc = 0.0f;\n    \n    // Loop over k-dimension tiles\n    for (int k_tile = 0; k_tile < (K + BLOCK_SIZE_K - 1) / BLOCK_SIZE_K; k_tile++) {\n        // Load A tile into shared memory\n        if (row < M && k_tile * BLOCK_SIZE_K + tx < K) {\n            As[ty][tx] = A[row * K + k_tile * BLOCK_SIZE_K + tx];\n        } else {\n            As[ty][tx] = 0.0f;\n        }\n        \n        // Load B tile into shared memory\n        if (k_tile * BLOCK_SIZE_K + ty < K && col < N) {\n            Bs[ty][tx] = B[(k_tile * BLOCK_SIZE_K + ty) * N + col];\n        } else {\n            Bs[ty][tx] = 0.0f;\n        }\n        \n        __syncthreads();\n        \n        // Compute dot product for this tile\n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE_K; k++) {\n            acc += As[ty][k] * Bs[k][tx];\n        }\n        \n        __syncthreads();\n    }\n    \n    // Write result to global memory\n    if (row < M && col < N) {\n        C[row * N + col] = acc;\n    }\n}\n\n// This function selects the best kernel based on input dimensions\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    // Make sure inputs are on GPU and contiguous\n    A = A.contiguous();\n    B = B.contiguous();\n    \n    const int M = A.size(0);\n    const int K = A.size(1);\n    const int N = B.size(1);\n    \n    // Create output tensor\n    auto options = torch::TensorOptions()\n        .dtype(A.dtype())\n        .device(A.device());\n    auto C = torch::empty({M, N}, options);\n    \n    // Choose kernel based on size\n    if (M >= 8192 && N >= 8192 && K <= 128) {\n        // For very large M,N and small K, use the register-based kernel\n        constexpr int BLOCK_SIZE_M = 128;\n        constexpr int BLOCK_SIZE_N = 128;\n        constexpr int TILE_SIZE = 8;\n        \n        dim3 threads(BLOCK_SIZE_N / TILE_SIZE, BLOCK_SIZE_M / TILE_SIZE);\n        dim3 blocks((N + BLOCK_SIZE_N - 1) / BLOCK_SIZE_N, (M + BLOCK_SIZE_M - 1) / BLOCK_SIZE_M);\n        \n        matmul_kernel_small_k_improved<BLOCK_SIZE_M, BLOCK_SIZE_N, TILE_SIZE><<<blocks, threads>>>(\n            A.data_ptr<float>(),\n            B.data_ptr<float>(),\n            C.data_ptr<float>(),\n            M, N, K\n        );\n    } else {\n        // For other sizes, use the shared memory kernel which has better cache behavior\n        constexpr int BLOCK_SIZE_M = 32;\n        constexpr int BLOCK_SIZE_N = 32;\n        constexpr int BLOCK_SIZE_K = 32;  // Should be min(32, K) ideally\n        \n        dim3 threads(BLOCK_SIZE_N, BLOCK_SIZE_M);\n        dim3 blocks((N + BLOCK_SIZE_N - 1) / BLOCK_SIZE_N, (M + BLOCK_SIZE_M - 1) / BLOCK_SIZE_M);\n        \n        matmul_kernel_small_k_shared<BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K><<<blocks, threads>>>(\n            A.data_ptr<float>(),\n            B.data_ptr<float>(),\n            C.data_ptr<float>(),\n            M, N, K\n        );\n    }\n    \n    return C;\n}\n\"\"\"\n\nmatmul_cpp_source = \"\"\"\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B);\n\"\"\"\n\n# Compile the inline CUDA code\ncustom_matmul = load_inline(\n    name=\"custom_matmul\",\n    cpp_sources=matmul_cpp_source,\n    cuda_sources=matmul_source,\n    functions=[\"matmul_cuda\"],\n    verbose=True,\n    extra_cflags=[\"-O3\"],\n    extra_cuda_cflags=[\n        \"-O3\", \n        \"--use_fast_math\",\n        \"-Xptxas=-v\",\n        \"--maxrregcount=128\"  # Control register usage\n    ],\n)\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model that performs a single matrix multiplication (C = A * B) with a small K dimension\n    using a custom CUDA kernel with multiple optimization strategies\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n        self.custom_matmul = custom_matmul\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs optimized matrix multiplication.\n\n        Args:\n            A: Input tensor of shape (M, K).\n            B: Input tensor of shape (K, N).\n\n        Returns:\n            Output tensor of shape (M, N).\n        \"\"\"\n        # Make sure inputs are on CUDA\n        A = A.cuda() if not A.is_cuda else A\n        B = B.cuda() if not B.is_cuda else B\n        \n        return self.custom_matmul.matmul_cuda(A, B)",
  "duration_seconds": 895.431973695755,
  "initial_seed_score": 0.0,
  "iteration_history": [
    {
      "iteration": 1,
      "best_score_so_far": 0.06817460317460318,
      "num_metric_calls_so_far": 4,
      "calls_this_iter": 3,
      "accepted_new_candidate": true,
      "new_candidate_score": 0.06817460317460318
    },
    {
      "iteration": 2,
      "best_score_so_far": 0.3064056939501779,
      "num_metric_calls_so_far": 7,
      "calls_this_iter": 3,
      "accepted_new_candidate": true,
      "new_candidate_score": 0.3064056939501779
    },
    {
      "iteration": 3,
      "best_score_so_far": 1.137748344370861,
      "num_metric_calls_so_far": 10,
      "calls_this_iter": 3,
      "accepted_new_candidate": true,
      "new_candidate_score": 1.1345646437994723
    },
    {
      "iteration": 4,
      "best_score_so_far": 1.137748344370861,
      "num_metric_calls_so_far": 12,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    },
    {
      "iteration": 5,
      "best_score_so_far": 1.1436170212765957,
      "num_metric_calls_so_far": 14,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    },
    {
      "iteration": 6,
      "best_score_so_far": 1.2067510548523206,
      "num_metric_calls_so_far": 17,
      "calls_this_iter": 3,
      "accepted_new_candidate": true,
      "new_candidate_score": 1.2067510548523206
    },
    {
      "iteration": 7,
      "best_score_so_far": 1.2067510548523206,
      "num_metric_calls_so_far": 19,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    },
    {
      "iteration": 8,
      "best_score_so_far": 1.2067510548523206,
      "num_metric_calls_so_far": 21,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    },
    {
      "iteration": 9,
      "best_score_so_far": 1.2067510548523206,
      "num_metric_calls_so_far": 23,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    },
    {
      "iteration": 10,
      "best_score_so_far": 1.2274678111587982,
      "num_metric_calls_so_far": 25,
      "calls_this_iter": 2,
      "accepted_new_candidate": false,
      "new_candidate_score": null
    }
  ],
  "val_aggregate_scores": [
    0.0,
    0.06817460317460318,
    0.3064056939501779,
    1.1345646437994723,
    1.2067510548523206
  ],
  "settings": {
    "reflection_lm": "anthropic/claude-3.7-sonnet",
    "max_iterations": 9,
    "reflection_minibatch_size": 1,
    "num_correct_trials": 1,
    "num_perf_trials": 5
  }
}