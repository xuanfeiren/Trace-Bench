{
  "task_idx": 4,
  "best_speedup": 0.9208860759493671,
  "num_metric_calls": 23,
  "best_at_metric_call": 14,
  "best_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# Define custom CUDA kernel for upper triangular matrix multiplication\ntriu_matmul_source = \"\"\"\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n\ntorch::Tensor triu_matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    // Get the dimensions\n    int N = A.size(0);\n    \n    // Create output tensor\n    auto options = torch::TensorOptions()\n        .dtype(A.dtype())\n        .device(A.device());\n    auto C = torch::zeros({N, N}, options);\n    \n    // Get pointers to data\n    float *d_A = A.data_ptr<float>();\n    float *d_B = B.data_ptr<float>();\n    float *d_C = C.data_ptr<float>();\n    \n    // Create cuBLAS handle\n    cublasHandle_t handle;\n    cublasCreate(&handle);\n    \n    // Set up alpha and beta for gemm\n    float alpha = 1.0f;\n    float beta = 0.0f;\n    \n    // Perform matrix multiplication using cuBLAS (much faster than our custom kernel)\n    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, \n                N, N, N, \n                &alpha,\n                d_B, N,    // Note: cuBLAS uses column-major order, so we swap A and B\n                d_A, N, \n                &beta,\n                d_C, N);\n    \n    // Destroy the handle\n    cublasDestroy(handle);\n    \n    // Apply upper triangular mask directly on the result\n    return torch::triu(C);\n}\n\"\"\"\n\ntriu_matmul_cpp_source = \"\"\"\ntorch::Tensor triu_matmul_cuda(torch::Tensor A, torch::Tensor B);\n\"\"\"\n\n# Compile the inline CUDA code\ntriu_matmul = load_inline(\n    name=\"triu_matmul\",\n    cpp_sources=triu_matmul_cpp_source,\n    cuda_sources=triu_matmul_source,\n    functions=[\"triu_matmul_cuda\"],\n    verbose=True,\n    extra_cflags=[\"-lcublas\"],\n    extra_ldflags=[\"-lcublas\"],\n    with_cuda=True\n)\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model that performs matrix multiplication for upper triangular matrices.\n    Uses cuBLAS for the matrix multiplication part which is much more optimized than\n    our custom implementation.\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n        self.triu_matmul = triu_matmul\n    \n    def forward(self, A, B):\n        \"\"\"\n        Performs optimized matrix multiplication for upper triangular matrices.\n\n        Args:\n            A (torch.Tensor): Upper triangular matrix of shape (N, N).\n            B (torch.Tensor): Upper triangular matrix of shape (N, N).\n\n        Returns:\n            torch.Tensor: The product of A and B, also an upper triangular matrix of shape (N, N).\n        \"\"\"\n        return self.triu_matmul.triu_matmul_cuda(A, B)",
  "num_candidates": 3,
  "duration_seconds": 901.5729117393494,
  "val_aggregate_scores": [
    0.0,
    0.6160337552742615,
    0.9208860759493671
  ],
  "settings": {
    "reflection_lm": "anthropic/claude-3.7-sonnet",
    "max_metric_calls": 10,
    "reflection_minibatch_size": 1,
    "num_correct_trials": 1,
    "num_perf_trials": 5
  }
}