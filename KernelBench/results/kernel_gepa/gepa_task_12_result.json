{
  "task_idx": 12,
  "best_speedup": 1.0423280423280423,
  "num_metric_calls": 23,
  "best_at_metric_call": 12,
  "best_cuda_code": "import torch\nimport torch.nn as nn\nfrom torch.utils.cpp_extension import load_inline\n\n# Define the custom CUDA kernel for matrix multiplication\nmatmul_source = \"\"\"\n#include <torch/extension.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    // Get tensor dimensions\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    \n    // Create output tensor\n    auto options = torch::TensorOptions()\n                      .dtype(A.dtype())\n                      .device(A.device());\n    auto C = torch::empty({M, N}, options);\n    \n    // Get data pointers\n    const float* a_ptr = A.data_ptr<float>();\n    const float* b_ptr = B.data_ptr<float>();\n    float* c_ptr = C.data_ptr<float>();\n    \n    // Initialize cuBLAS\n    cublasHandle_t handle;\n    cublasCreate(&handle);\n    \n    // Set math mode to use Tensor Cores if available\n    cublasSetMathMode(handle, CUBLAS_TENSOR_OP_MATH);\n    \n    // Constants for GEMM operation\n    const float alpha = 1.0f;\n    const float beta = 0.0f;\n    \n    // Use cublasGemmEx for better performance with TensorCores\n    cublasGemmEx(handle,\n                 CUBLAS_OP_N, CUBLAS_OP_N,\n                 N, M, K,\n                 &alpha,\n                 b_ptr, CUDA_R_32F, N,\n                 a_ptr, CUDA_R_32F, K,\n                 &beta,\n                 c_ptr, CUDA_R_32F, N,\n                 CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP);\n    \n    // Destroy cuBLAS handle\n    cublasDestroy(handle);\n    \n    return C;\n}\n\n// Specialized function for blocked matrix multiplication for large K dimensions\ntorch::Tensor blocked_matmul_cuda(torch::Tensor A, torch::Tensor B) {\n    // Get tensor dimensions\n    int M = A.size(0);\n    int K = A.size(1);\n    int N = B.size(1);\n    \n    // Create output tensor\n    auto options = torch::TensorOptions()\n                      .dtype(A.dtype())\n                      .device(A.device());\n    auto C = torch::zeros({M, N}, options);\n    \n    // Get data pointers\n    const float* a_ptr = A.data_ptr<float>();\n    const float* b_ptr = B.data_ptr<float>();\n    float* c_ptr = C.data_ptr<float>();\n    \n    // Initialize cuBLAS\n    cublasHandle_t handle;\n    cublasCreate(&handle);\n    cublasSetMathMode(handle, CUBLAS_TENSOR_OP_MATH);\n    \n    // Constants for GEMM operation\n    const float alpha = 1.0f;\n    const float beta = 1.0f; // Accumulate results\n    \n    // Define block size for K dimension (adjust based on GPU memory)\n    int block_size = 16384; // 16K, adjust as needed\n    int num_blocks = (K + block_size - 1) / block_size;\n    \n    // Process the matrix multiplication in blocks along K dimension\n    for (int i = 0; i < num_blocks; i++) {\n        int k_start = i * block_size;\n        int k_size = std::min(block_size, K - k_start);\n        \n        // Point to the correct segment of A\n        const float* a_block = a_ptr + k_start;\n        // Point to the correct segment of B\n        const float* b_block = b_ptr + k_start * N;\n        \n        // Use cublasGemmEx for better performance with TensorCores\n        cublasGemmEx(handle,\n                    CUBLAS_OP_N, CUBLAS_OP_N,\n                    N, M, k_size,\n                    &alpha,\n                    b_block, CUDA_R_32F, N,\n                    a_block, CUDA_R_32F, K,\n                    &beta,\n                    c_ptr, CUDA_R_32F, N,\n                    CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP);\n    }\n    \n    // Destroy cuBLAS handle\n    cublasDestroy(handle);\n    \n    return C;\n}\n\"\"\"\n\nmatmul_cpp_source = \"\"\"\ntorch::Tensor matmul_cuda(torch::Tensor A, torch::Tensor B);\ntorch::Tensor blocked_matmul_cuda(torch::Tensor A, torch::Tensor B);\n\"\"\"\n\n# Compile the inline CUDA code for matrix multiplication\nmatmul_module = load_inline(\n    name=\"matmul_module\",\n    cpp_sources=matmul_cpp_source,\n    cuda_sources=matmul_source,\n    functions=[\"matmul_cuda\", \"blocked_matmul_cuda\"],\n    verbose=True,\n    extra_cuda_cflags=[\"-lcublas\"],\n    with_cuda=True\n)\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model that performs matrix multiplication using custom CUDA kernel\n    with blocking for large K dimensions\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n        self.matmul_module = matmul_module\n        self.k_threshold = 100000  # Threshold to decide when to use blocked multiplication\n    \n    def forward(self, A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs matrix multiplication of A and B using custom CUDA kernel.\n        Uses blocked multiplication for large K dimensions.\n\n        Args:\n            A: Input tensor of shape (M, K)\n            B: Input tensor of shape (K, N)\n\n        Returns:\n            Output tensor of shape (M, N)\n        \"\"\"\n        # Move tensors to GPU if they're not already there\n        if not A.is_cuda:\n            A = A.cuda()\n        if not B.is_cuda:\n            B = B.cuda()\n        \n        # Use blocked multiplication for large K dimensions\n        if A.size(1) > self.k_threshold:\n            return self.matmul_module.blocked_matmul_cuda(A, B)\n        else:\n            return self.matmul_module.matmul_cuda(A, B)\n\ndef get_inputs():\n    A = torch.rand(M, K).cuda()\n    B = torch.rand(K, N).cuda()\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed",
  "num_candidates": 3,
  "duration_seconds": 971.5041000843048,
  "val_aggregate_scores": [
    0.0,
    0.9292452830188679,
    1.0423280423280423
  ],
  "settings": {
    "reflection_lm": "anthropic/claude-3.7-sonnet",
    "max_metric_calls": 10,
    "reflection_minibatch_size": 1,
    "num_correct_trials": 1,
    "num_perf_trials": 5
  }
}